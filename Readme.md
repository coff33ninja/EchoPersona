# üéôÔ∏è EchoPersona
**Proof of Concept: Custom TTS/STT with Character Voices**

## üöÄ Overview
This project is a full-stack playground for Text-to-Speech (TTS) and Speech-to-Text (STT) enthusiasts. It empowers you to:

- üéß **Structure Voice Data**: Includes a **proof-of-concept** custom downloader (`genshin_voice_downloader.py`) to fetch and structure character voice data from publicly available web sources¬π. This component may be removed in future versions.
- üóÇÔ∏è **Manage Datasets**: Organize and preprocess voice data per character.
- üß† **Train Custom TTS Models**: Build personalized TTS models for each character using their voice samples, with options to resume training from checkpoints.
- üó£Ô∏è **Generate Speech**: Use trained models to synthesize dialogue in a character‚Äôs voice.
- üõ†Ô∏è **Standard Tools Built-In**: Includes classic TTS (pyttsx3, gTTS), STT (Whisper, Google), and voice cloning (XTTS).

---

## üß© Key Concepts

**Character**: Represents a unique voice persona. All associated audio, metadata, and models live in folders named after them.
**Base Directories**:
- `voice_datasets/` ‚Äì Raw audio data per character (e.g., `voice_datasets/Arlecchino/`).
- `trained_models/` ‚Äì Output from model training (e.g., `trained_models/Arlecchino/`).

---

## üåü Features

### üîÅ Character-Specific Workflow
- Manage and train voice models per character.
- Includes the proof-of-concept downloader to help structure initial data.

### üß∞ Dataset Management (`voice_trainer_cli.py`)
- Record new samples.
- Add/annotate existing WAV/MP3 files.
- Validate dataset metadata.
- View stats: duration, sample count, format consistency.
- Augment audio (pitch, speed, noise).
- Trim silence and check audio quality.

### üéì Model Training
Train VITS-based models with `voice_clone_train.py` via the CLI or GUI. Supports:
- Custom epochs, batch size, learning rate.
- Resuming from checkpoints (`--continue_path`).
- Phoneme-based training (`--use_phonemes`, `--phoneme_language`).
- Adjustable sample rate (`--sample_rate`).

### üí¨ Generate TTS
Use trained models to create character-specific speech outputs.

### üéôÔ∏è STT Support
Use Whisper (recommended) or other engines to transcribe any audio file.

### üé§ Pre-Trained Voice Cloning
Use XTTSv2 and other tools to clone voices from reference samples.

---

## üéµ Audio Playback
- Play audio files using `pydub` or `simpleaudio` via helper functions.
- Supports WAV and MP3 formats.

---

## üéõÔ∏è Audio Preprocessing
- Trim silence from audio files.
- Augment audio with background noise or pitch/speed adjustments.
- Validate audio quality for consistency.

---

## üõ†Ô∏è Installation

```bash
git clone https://github.com/USER/EchoPersona.git
cd EchoPersona
pip install -r requirements.txt
```

> ‚ö†Ô∏è **Note**:
- `openai-whisper` requires `ffmpeg` installed and accessible in your system's PATH.
- Coqui TTS (`TTS` package) may have specific OS/CUDA requirements. Check their [documentation](https://github.com/coqui-ai/TTS).
- Whisper models download on first use to `~/.cache/whisper`.
- For Vosk STT, download models manually from the [Vosk website](https://alphacephei.com/vosk/models).

---

## üìÅ Folder Structure

```
EchoPersona/
‚îú‚îÄ‚îÄ voice_datasets/
‚îÇ   ‚îú‚îÄ‚îÄ Arlecchino/           # Character dataset folder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metadata.csv      # Format: audio_file|text|speaker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_Arlecchino_001.wav
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ trained_models/
‚îÇ   ‚îú‚îÄ‚îÄ Arlecchino/           # Character model output folder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training.log      # Training log file
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ best_model.pth    # Trained model weights
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_model.pth   # Final model weights
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.json       # Model configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_config.json # Final configuration
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run-YYYYMMDD/    # Checkpoint folder (e.g., run-20250415)
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checkpoint.pth
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vocabulary.txt    # Phoneme vocabulary
‚îú‚îÄ‚îÄ logs/                      # Secondary logs (if used)
‚îú‚îÄ‚îÄ enhanced_logger.py         # Optional logging script
‚îú‚îÄ‚îÄ genshin_voice_downloader.py # Proof-of-concept downloader
‚îú‚îÄ‚îÄ genshin_voice_retranscriber.py # Optional re-transcription script
‚îú‚îÄ‚îÄ voice_trainer_cli.py       # CLI for dataset and training
‚îú‚îÄ‚îÄ voice_trainer_gui.py       # GUI application
‚îú‚îÄ‚îÄ voice_tools.py             # Core utilities
‚îú‚îÄ‚îÄ voice_clone_train.py       # Core training script
‚îú‚îÄ‚îÄ test_trained_model.py      # Test script for trained models
‚îú‚îÄ‚îÄ test_voice_tools.py        # Unit tests
‚îú‚îÄ‚îÄ requirements.txt           # Dependencies
‚îú‚îÄ‚îÄ background_noise.mp3       # Example noise for augmentation
‚îú‚îÄ‚îÄ Readme.md                  # This file
‚îî‚îÄ‚îÄ logo.png
```

---

## üß™ Usage Workflow

### 1. üîª Structure Initial Voice Data (Optional)

```bash
python genshin_voice_downloader.py --character "Arlecchino" --output_dir voice_datasets
```
> **Note**: `genshin_voice_downloader.py` is a **proof-of-concept** to demonstrate structuring data from web sources¬π and may be removed in the future. Use responsibly.

Creates `voice_datasets/Arlecchino/` with WAVs and `metadata.csv`. The script uses Whisper for transcription.

> **Alternative**: Manually create `voice_datasets/Arlecchino/` with `metadata.csv` (format: `filename.wav|Transcription text|Arlecchino`) and audio files.

---

### 2. üß∞ Manage Dataset

Use `--character <Name>` with all `voice_trainer_cli.py` actions:

- **Record New Samples**:
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action record
  ```

- **Add Existing Audio** (Prompts for transcription):
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action provide --file "/path/to/audio.wav"
  ```

- **Validate Metadata** (Checks format & file existence):
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action validate
  ```

- **View Stats** (Duration, file count, format warnings):
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action stats
  ```

- **Augment File** (Adds pitch/speed variation or noise):
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action augment --file "sample_Arlecchino_001.wav"
  ```

- **Trim Silence**:
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action trim --file "sample_Arlecchino_001.wav"
  ```

---

### 3. üß† Train the Model

Training uses `voice_clone_train.py` internally. Run via CLI or GUI.

- **Via CLI**:
  ```bash
  # Basic command
  python voice_trainer_cli.py --character "Arlecchino" --action train

  # With custom parameters
  python voice_trainer_cli.py --character "Arlecchino" --action train --epochs 500 --batch_size 8 --learning_rate 0.0001 --base_dataset_dir "voice_datasets" --base_model_dir "trained_models" --sample_rate 22050 --use_phonemes true --phoneme_language en-us
  ```

  - **Resuming Training**:
    ```bash
    python voice_trainer_cli.py --character "Arlecchino" --action train --continue_path "trained_models/Arlecchino/run-YYYYMMDD"
    ```
    > **Note**: Ensure the `--continue_path` folder (e.g., `run-YYYYMMDD`) exists and contains a valid checkpoint (e.g., `checkpoint.pth`). Check `trained_models/Arlecchino/` for available runs.

- **Via GUI (`voice_trainer_gui.py`)**:
  - Select the character and `train` action.
  - Adjust sliders for epochs, batch size, learning rate, sample rate.
  - Specify `--continue_path` if resuming.
  - Click "Start Training".

**Output**: Model files (`best_model.pth`, `final_model.pth`, `config.json`, `final_config.json`), logs (`training.log`), and checkpoints (`run-YYYYMMDD/`) in `trained_models/Arlecchino/`.

#### **Training Parameters**:
- **`--epochs`** (Default: 100): Number of dataset passes. Higher values improve quality but risk overfitting.
- **`--batch_size`** (Default: 16): Samples per batch. Reduce (e.g., 8, 4) for memory errors.
- **`--learning_rate`** (Default: 0.001): Weight adjustment step. Lower (e.g., 0.0001) for stability.
- **`--base_dataset_dir`** (Default: `voice_datasets`): Path to dataset folder.
- **`--base_model_dir`** (Default: `trained_models`): Path for model outputs.
- **`--continue_path`** (Optional): Path to checkpoint folder (e.g., `trained_models/Arlecchino/run-YYYYMMDD`) to resume training.
- **`--sample_rate`** (Default: 22050): Audio sample rate (Hz). Match your dataset‚Äôs rate.
- **`--use_phonemes`** (Default: true): Use phonemes for better pronunciation.
- **`--phoneme_language`** (Default: en-us): Language for phonemes (required if `--use_phonemes true`).

#### **Troubleshooting Training**:
- **Error: "No models found in continue path"**:
  - Verify the `--continue_path` exists (e.g., `trained_models/Arlecchino/run-YYYYMMDD`).
  - Check for `checkpoint.pth` or similar files in the folder.
  - If incorrect or missing, remove `--continue_path` to start fresh or use the correct run folder.
  - Example: List runs with `dir trained_models\Arlecchino\run-*` (Windows).
- **CUDA Out of Memory**: Reduce `--batch_size` (e.g., 8 or 4).
- **Metadata Errors**: Run `--action validate` to check `metadata.csv`.
- **Training Fails**: Check `trained_models/Arlecchino/training.log` for details (e.g., file not found, phoneme issues).
- **Slow Data Loading**: Set `--num_loader_workers 0` in `voice_clone_train.py`.
- **Test Subset**: Try `--epochs 10` with a few files to debug.
- **Dependencies**: Ensure `ffmpeg`, PyTorch, and CUDA (if using GPU) are compatible.

---

### 4. üó£Ô∏è Use the Trained Voice

- **Quick Test**:
  ```bash
  python voice_trainer_cli.py --character "Arlecchino" --action use --text "This is a test."
  ```

- **Manual Test**:
  ```bash
  python test_trained_model.py --character "Arlecchino" --text "Testing directly." --output_file "output.wav"
  ```

---

### 5. üîÑ Re-attempt Transcription (Optional)

For files with `<transcription_failed>` in `metadata.csv`:
- Use `genshin_voice_retranscriber.py` (if available).
- Or manually edit `metadata.csv` and use `--action provide`.

---

### 6. üîé General Speech-to-Text (STT)

```bash
python voice_tools.py
# Select character for structure
# Choose Option 11 for STT on any file
```

---

### 7. üß™ Interactive Menu

```bash
python voice_tools.py
```

Guided menu for training, testing, cloning, and transcription.

---

## ‚ö†Ô∏è Notes and Best Practices

- **Paths**: Use absolute paths for `--base_dataset_dir`, `--base_model_dir`, `--continue_path` on Windows (e.g., `C:\Users\USER\Documents\GitHub\EchoPersona\voice_datasets`).
- **Integers**: Ensure `--epochs`, `--batch_size`, `--sample_rate` are integers.
- **Logs**: Always check `trained_models/<Character>/training.log` for errors.
- **Dataset**: Validate `metadata.csv` format (`audio_file|text|speaker`) before training.
- **Hardware**: Adjust `--batch_size` and `--num_loader_workers` based on your CPU/GPU.

---

## üß™ Testing

```bash
python test_voice_tools.py
python test_trained_model.py
```

---

## üßæ Dependencies (`requirements.txt`)

- `TTS` (Coqui TTS)
- `SpeechRecognition`
- `openai-whisper`
- `pydub`, `sounddevice`, `librosa`, `numpy`, `scipy`, `torch`
- `ffmpeg` (external, install separately)

---

## ü§ù Contributing

Pull requests welcome! Open an issue or fork to experiment.

---

## ‚ö†Ô∏è Disclaimer

The voice data downloader (`genshin_voice_downloader.py`) is a **technical proof-of-concept** to demonstrate fetching and structuring data from publicly available web sources¬π. It relies on third-party APIs and website structures that may change and **may be removed in future updates**.

Voice data from external sources **may be subject to copyright**. Users must comply with relevant licenses and terms. This project:
- ‚ùå Does **not endorse** copyright infringement.
- ‚úÖ Supports **personal, educational, non-commercial** use under fair use.
- üì¶ Ships **no pre-trained models** derived from the downloader.
- ‚ö†Ô∏è Generated audio should not misrepresent or impersonate without consent.

---
¬π Data sourced primarily from Genshin Impact Fandom Wiki (`genshin-impact.fandom.com`) and `genshin.jmp.blue` API. Thanks to these communities for public access.

## üìù License

MIT License ‚Äî hack, build, remix. Just don‚Äôt be evil.

---
